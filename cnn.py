# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gn_UfmZ9QPEpLXeXDc9S2HT7es3pKBIF
"""

# Import required libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import warnings
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
tf.random.set_seed(42)
np.random.seed(42)

print("TensorFlow version:", tf.__version__)
print("GPU Available:", len(tf.config.experimental.list_physical_devices('GPU')) > 0)

# =============================================================================
# 1. DATA LOADING & PREPROCESSING
# =============================================================================

print("\n" + "="*50)
print("1. LOADING AND PREPROCESSING DATA")
print("="*50)

# Load CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

# CIFAR-10 class names
class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',
               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

print(f"Training data shape: {x_train.shape}")
print(f"Training labels shape: {y_train.shape}")
print(f"Test data shape: {x_test.shape}")
print(f"Test labels shape: {y_test.shape}")
print(f"Number of classes: {len(class_names)}")

# Normalize pixel values to range [0, 1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# One-hot encode the labels
y_train_categorical = keras.utils.to_categorical(y_train, 10)
y_test_categorical = keras.utils.to_categorical(y_test, 10)

print(f"\nAfter preprocessing:")
print(f"Training data range: [{x_train.min():.2f}, {x_train.max():.2f}]")
print(f"Labels shape after one-hot encoding: {y_train_categorical.shape}")

# Visualize sample images from each class
plt.figure(figsize=(15, 8))
for i in range(10):
    # Find first occurrence of each class
    idx = np.where(y_train == i)[0][0]
    plt.subplot(2, 5, i + 1)
    plt.imshow(x_train[idx])
    plt.title(f'{class_names[i]}')
    plt.axis('off')
plt.suptitle('Sample Images from Each CIFAR-10 Class', fontsize=16)
plt.tight_layout()
plt.show()

# =============================================================================
# 2. CNN ARCHITECTURE DESIGN
# =============================================================================

print("\n" + "="*50)
print("2. BUILDING CNN ARCHITECTURE")
print("="*50)

def create_cnn_model(input_shape=(32, 32, 3), num_classes=10):
    """
    Creates a CNN model for CIFAR-10 classification

    Args:
        input_shape: Shape of input images (height, width, channels)
        num_classes: Number of output classes

    Returns:
        Compiled Keras model
    """

    model = keras.Sequential([
        # First Convolutional Block
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # Second Convolutional Block
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # Third Convolutional Block
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # Flatten and Fully Connected Layers
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')  # Output layer
    ])

    return model

# Create the model
model = create_cnn_model()

# Display model architecture
print("Model Architecture:")
model.summary()

# Visualize model architecture
keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, dpi=100)
plt.show()

# =============================================================================
# 3. MODEL COMPILATION & TRAINING
# =============================================================================

print("\n" + "="*50)
print("3. COMPILING AND TRAINING THE MODEL")
print("="*50)

# Compile the model
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Define callbacks for better training
callbacks = [
    # Reduce learning rate when validation loss plateaus
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=5,
        min_lr=0.0001,
        verbose=1
    ),
    # Early stopping to prevent overfitting
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1
    )
]

# Train the model
print("Starting training...")
history = model.fit(
    x_train, y_train_categorical,
    batch_size=32,
    epochs=2,  # Will stop early if no improvement
    validation_data=(x_test, y_test_categorical),
    callbacks=callbacks,
    verbose=1
)

print("Training completed!")

# =============================================================================
# 4. MODEL EVALUATION
# =============================================================================

print("\n" + "="*50)
print("4. EVALUATING MODEL PERFORMANCE")
print("="*50)

# Evaluate on test data
test_loss, test_accuracy = model.evaluate(x_test, y_test_categorical, verbose=0)
print(f"Test Accuracy: {test_accuracy:.4f}")
print(f"Test Loss: {test_loss:.4f}")

# Make predictions
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test_categorical, axis=1)

# Classification Report
print("\nClassification Report:")
print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))

# Confusion Matrix
plt.figure(figsize=(12, 10))
cm = confusion_matrix(y_true_classes, y_pred_classes)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix - CIFAR-10 CNN Classification')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# Calculate per-class accuracy
class_accuracy = cm.diagonal() / cm.sum(axis=1)
print("\nPer-class Accuracy:")
for i, acc in enumerate(class_accuracy):
    print(f"{class_names[i]}: {acc:.4f}")

# =============================================================================
# 5. TRAINING VISUALIZATION
# =============================================================================

print("\n" + "="*50)
print("5. VISUALIZING TRAINING PROGRESS")
print("="*50)

# Plot training history
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# Accuracy plot
ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)
ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)
ax1.set_title('Model Accuracy Over Time')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Loss plot
ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)
ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)
ax2.set_title('Model Loss Over Time')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Loss')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# =============================================================================
# 6. SAMPLE PREDICTIONS VISUALIZATION
# =============================================================================

print("\n" + "="*50)
print("6. VISUALIZING SAMPLE PREDICTIONS")
print("="*50)

def plot_sample_predictions(model, x_test, y_test, class_names, num_samples=12):
    """
    Plot sample predictions with true vs predicted labels
    """
    # Select random samples
    indices = np.random.choice(len(x_test), num_samples, replace=False)

    # Make predictions
    predictions = model.predict(x_test[indices])
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = y_test[indices].flatten()

    # Plot results
    fig, axes = plt.subplots(3, 4, figsize=(16, 12))
    axes = axes.ravel()

    for i in range(num_samples):
        # Display image
        axes[i].imshow(x_test[indices[i]])

        # Get prediction confidence
        confidence = np.max(predictions[i]) * 100

        # Set title with true vs predicted labels
        true_label = class_names[true_classes[i]]
        pred_label = class_names[predicted_classes[i]]

        # Color: green if correct, red if incorrect
        color = 'green' if true_classes[i] == predicted_classes[i] else 'red'

        axes[i].set_title(f'True: {true_label}\nPred: {pred_label}\nConf: {confidence:.1f}%',
                         color=color, fontsize=10)
        axes[i].axis('off')

    plt.suptitle('Sample Predictions: True vs Predicted Labels', fontsize=16)
    plt.tight_layout()
    plt.show()

    # Print accuracy for these samples
    correct_predictions = np.sum(true_classes == predicted_classes)
    sample_accuracy = correct_predictions / num_samples
    print(f"Accuracy on displayed samples: {sample_accuracy:.2%} ({correct_predictions}/{num_samples})")

# Show sample predictions
plot_sample_predictions(model, x_test, y_test, class_names)

# =============================================================================
# 7. ADDITIONAL ANALYSIS
# =============================================================================

print("\n" + "="*50)
print("7. ADDITIONAL ANALYSIS")
print("="*50)

# Top-k accuracy analysis
def calculate_top_k_accuracy(y_true, y_pred, k=3):
    """Calculate top-k accuracy"""
    top_k_pred = np.argsort(y_pred, axis=1)[:, -k:]
    correct = 0
    for i in range(len(y_true)):
        if y_true[i] in top_k_pred[i]:
            correct += 1
    return correct / len(y_true)

top_3_accuracy = calculate_top_k_accuracy(y_true_classes, y_pred, k=3)
print(f"Top-3 Accuracy: {top_3_accuracy:.4f}")

# Model complexity analysis
total_params = model.count_params()
trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_variables])
print(f"Total parameters: {total_params:,}")
print(f"Trainable parameters: {trainable_params:,}")

# Training efficiency
total_epochs = len(history.history['loss'])
best_val_acc = max(history.history['val_accuracy'])
print(f"Training stopped after {total_epochs} epochs")
print(f"Best validation accuracy: {best_val_acc:.4f}")

print("\n" + "="*50)
print("ANALYSIS COMPLETE!")
print("="*50)
print("Key Results:")
print(f"• Final Test Accuracy: {test_accuracy:.4f}")
print(f"• Top-3 Test Accuracy: {top_3_accuracy:.4f}")
print(f"• Best Validation Accuracy: {best_val_acc:.4f}")
print(f"• Total Training Epochs: {total_epochs}")
print(f"• Model Parameters: {total_params:,}")
print("="*50)

